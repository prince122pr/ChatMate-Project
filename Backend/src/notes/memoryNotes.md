# AI Memory System: Short-Term vs Long-Term

## 1. Short-Term Memory (MongoDB)
- Stores **recent chats** only.  
- Example: last 10â€“20 user & AI messages.  
- Fast to access â†’ used for immediate conversation context.  
- Works just like a humanâ€™s *working memory*.  

---

## 2. Long-Term Memory (Pinecone / Vector DB)
- Stores **all past conversations** in vector format.  
- Optimized for **semantic search** (similar meaning search).  
- Works like a humanâ€™s *long-term memory bank*.  

---

## 3. Flow of Answer Retrieval
1. **Check Short-Term Memory first**  
   - If the recent conversation already has the answer â†’ use it.  
   - `queryMemory()` is **not called**.  

2. **If not found in Short-Term Memory**  
   - Then `queryMemory()` is triggered.  
   - Pinecone (vector DB) is searched for relevant past context.  
   - The retrieved memory is added to AIâ€™s input before generating a reply.  

---

## 4. Analogy with Human Brain ğŸ§ 
- **Short-Term Memory** â†’ â€œWhat we just talked aboutâ€  
- **Long-Term Memory** â†’ â€œSomething we discussed weeks agoâ€  
- Process:  
  - If I remember it right now â†’ answer immediately.  
  - If not, I recall from deep memory.  

---

## 6. Key Point
âœ… **If the answer is found in Short-Term Memory â†’ no need to call Pinecone.**  
âŒ Only when Short-Term Memory fails â†’ `queryMemory()` searches Long-Term Memory.  
